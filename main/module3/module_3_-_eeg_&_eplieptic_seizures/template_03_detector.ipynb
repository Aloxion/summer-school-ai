{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d36d77b",
   "metadata": {},
   "source": [
    "# Experimentation 3: Seizure Detection\n",
    "\n",
    "## Structure\n",
    "1. Data preparation (pre-processing)<br/>\n",
    "   Note: ideally you store the pre-processed data in template 02 and load it here again, instead of duplicating the code …\n",
    "2. Windowing\n",
    "3. Feature & label extraction\n",
    "4. Data split\n",
    "5. FV-pre-processing\n",
    "6. Classifier creation\n",
    "7. Evaluation\n",
    "\n",
    "\n",
    "## Reporting\n",
    "Not every plot or number generated in this template comes into the report.\n",
    "Nonetheless, some intermediary steps are required to achieve the relevant results.\n",
    "Cells, which have a *direct* relation to a part of the report, \n",
    "are marked with **Report:**.\n",
    "Be sure to not jump over relevant precursor steps.\n",
    "But when having little time, think about your priorities, and try to avoid spending time on decorative steps or cells which are not needed for the report.\n",
    "\n",
    "The relevant information about what to include in the report is the corresponding pdf document on itslearning.\n",
    "Annotations in this file are just for orientation and might not be complete.\n",
    "\n",
    "\n",
    "\n",
    "## What to do\n",
    "  - Build it up step by step, i.e\n",
    "      * First take a short look at how the pipeline looks like\n",
    "      * Initially, use the raw window as feature vector for starters to get everything going\n",
    "      * Implement the overlap of the window with the seizure,\n",
    "        so that you have a label\n",
    "      * Only then start implementing features\n",
    "      * Then, you can go on\n",
    "  - There are many parameters which influence the outcome\n",
    "      * Which influence does balancing have?\n",
    "      * How about scaling?\n",
    "      * And PCA with / without whitening?\n",
    "      * Try to get a feeling for how the PCA changes the channels, \n",
    "        i.e., plot consecutive channels on x/y axis.\n",
    "        Colour the dots according to their labels.\n",
    "      * How do your observations relate to your expectations?\n",
    "  - Investigate the relevance of features\n",
    "  - Without doing a proper evaluation, do you think that the relevance of the features correlates with the computaton time going into deriving them?\n",
    "  \n",
    "## Discussion\n",
    "In your group or with your neighbours\n",
    "- Which influence does the data preparation have? I.e., normalisation, PCA, whitening?\n",
    "- When comparing the use of PCA here to Module 2, how would you describe the interpretability of the dimensions?\n",
    "- Which performance do you achieve? Is the detector usable?\n",
    "- Reflecting on the performance of the detector, for which tasks would you trust this model? How would you like to change the performance for possible use cases?\n",
    "\n",
    "## When you are done with all other tasks…\n",
    "You can check template 3a for optional tasks to dig deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f26b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyedflib import highlevel\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Jupyter lab supports interactive plots      # Matplotlib for plotting\n",
    "# using \"widget\"\n",
    "#%matplotlib widget\n",
    "\n",
    "# Jupyter lab doesn't support notebook,\n",
    "# which was the preferred method for jupyter notebooks.\n",
    "#%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "# Adjust plot size & resolution for inline display.\n",
    "# Tune to your needs.\n",
    "plt.rcParams['figure.figsize'] = [9, 5.56]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f835c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['template_03_detector.ipynb', 'jupyter_notebook_templates', 'task1.ipynb', 'view-data.py', 'work', 'seizure_eeg_data', 'data', 'EEG_References.md']\n"
     ]
    }
   ],
   "source": [
    "# Defining base paths for read-only and read-write data\n",
    "# will make it easy for us to switch between cloud\n",
    "# and local environments by just adjusting the paths.\n",
    "#\n",
    "# Also, it will prevent accidental overwriting of read-only data.\n",
    "#\n",
    "# The example codes starting with '/work' relate to UCloud.\n",
    "# Note that jupyterlab in ucloud will not show you the /work folder.\n",
    "# What jupyterlab shows as origin */* of the filesystem\n",
    "# is in reality the */work* folder.\n",
    "import os\n",
    "print(os.listdir('./'))\n",
    "from pathlib import Path         # OS agnostic path handling (/ vs \\)\n",
    "# Current directory\n",
    "# Base directories\n",
    "# DATA_DIR -- where the read-only sources are\n",
    "DATA_DIR = Path('./work/data')\n",
    "\n",
    "# OUTPUT_DIR -- where we will keep our data (read/write)\n",
    "# We will make sure it exists!\n",
    "OUTPUT_DIR = Path('./work/output')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a903a",
   "metadata": {},
   "source": [
    "# Loading the Data\n",
    "While this template replicates the boxes from template 02, it is advised to store the pre-processed data in template 02 and then load it again here, preventing you from duplicating all the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eda4335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ ['jupyter_notebook_templates', 'work', 'seizure_eeg_data', 'data'] ['template_03_detector.ipynb', 'task1.ipynb', 'view-data.py', 'EEG_References.md']\n",
      "./jupyter_notebook_templates ['extra_challenges', 'solutions'] ['template_03_detector.ipynb']\n",
      "./jupyter_notebook_templates/extra_challenges ['.ipynb_checkpoints'] ['template_03a_optional_investigations_for_classification.ipynb', 'template_04_fourier.ipynb', 'template_04a_optional_investigations_using_the_spectrum.ipynb']\n",
      "./jupyter_notebook_templates/extra_challenges/.ipynb_checkpoints [] ['template_04_fourier-checkpoint.ipynb', 'template_04a_optional_investigations_using_the_spectrum-checkpoint.ipynb', 'template_03a_optional_investigations_for_classification-checkpoint.ipynb']\n",
      "./jupyter_notebook_templates/solutions [] []\n",
      "./work ['output', 'data'] []\n",
      "./work/output [] []\n",
      "./work/data ['seizure_eeg_data'] []\n",
      "./work/data/seizure_eeg_data [] ['04.edf', '01.edf', '03.edf', '02.edf', 'num_seizures.txt']\n",
      "./seizure_eeg_data [] ['04.edf', '01.edf', '03.edf', '02.edf', 'num_seizures.txt']\n",
      "./data ['test', 'train'] []\n",
      "./data/test [] ['13.tif', '12.tif', '10.tif', '11.tif', '15.tif', '29.tif', '28.tif', '14.tif', '16.tif', '17.tif', '9.tif', '8.tif', '3.tif', '2.tif', '0.tif', '1.tif', '5.tif', '4.tif', '6.tif', '7.tif', '26.tif', '27.tif', '19.tif', '25.tif', '24.tif', '18.tif', '20.tif', '21.tif', '23.tif', '22.tif']\n",
      "./data/train ['images', 'labels'] []\n",
      "./data/train/images [] ['13.tif', '12.tif', '10.tif', '11.tif', '15.tif', '29.tif', '28.tif', '14.tif', '16.tif', '17.tif', '9.tif', '8.tif', '3.tif', '2.tif', '0.tif', '1.tif', '5.tif', '4.tif', '6.tif', '7.tif', '26.tif', '27.tif', '19.tif', '25.tif', '24.tif', '18.tif', '20.tif', '21.tif', '23.tif', '22.tif']\n",
      "./data/train/labels [] ['13.tif', '12.tif', '10.tif', '11.tif', '15.tif', '29.tif', '28.tif', '14.tif', '16.tif', '17.tif', '9.tif', '8.tif', '3.tif', '2.tif', '0.tif', '1.tif', '5.tif', '4.tif', '6.tif', '7.tif', '26.tif', '27.tif', '19.tif', '25.tif', '24.tif', '18.tif', '20.tif', '21.tif', '23.tif', '22.tif']\n",
      "Reading EEG from: work/data/seizure_eeg_data/01.edf\n",
      "work/data/seizure_eeg_data/01.edf\n"
     ]
    }
   ],
   "source": [
    "# Loading file:\n",
    "fn = DATA_DIR / \\\n",
    "    'seizure_eeg_data/' \\\n",
    "    '01.edf'\n",
    "\n",
    "for subdir, dir, files in os.walk('./'):\n",
    "    print(subdir, dir, files)\n",
    "print('Reading EEG from: {}'.format(fn))\n",
    "print(str(fn))\n",
    "raw_signals, signal_headers, header = \\\n",
    "    highlevel.read_edf(str(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea2f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotations:\n",
    "# In seconds since start of recording,\n",
    "# use singal_headers.sample_frequency to map to sample numbers\n",
    "seizures = list()\n",
    "for start, duration, kind in header['annotations']:\n",
    "    if kind == 'Seizure':\n",
    "        seizures.append((start, float(duration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f287c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel  0: EEG Fp1-REF\n",
      "Channel  1: EEG Fp2-REF\n",
      "Channel  2: EEG F3-REF\n",
      "Channel  3: EEG F4-REF\n",
      "Channel  4: EEG C3-REF\n",
      "Channel  5: EEG C4-REF\n",
      "Channel  6: EEG P3-REF\n",
      "Channel  7: EEG P4-REF\n",
      "Channel  8: EEG O1-REF\n",
      "Channel  9: EEG O2-REF\n",
      "Channel 10: EEG F7-REF\n",
      "Channel 11: EEG F8-REF\n",
      "Channel 12: EEG T3-REF\n",
      "Channel 13: EEG T4-REF\n",
      "Channel 14: EEG T5-REF\n",
      "Channel 15: EEG T6-REF\n",
      "Channel 16: EEG Zyg_1-REF\n",
      "Channel 17: EEG Zyg_2-REF\n",
      "Channel 18: EEG Fz-REF\n",
      "Channel 19: EEG Cz-REF\n",
      "Channel 20: EEG Pz-REF\n",
      "Channel 21: EEG F10-REF\n",
      "Channel 22: EEG F9-REF\n",
      "Channel 23: EEG P9-REF\n",
      "Channel 24: ECG EKG1-REF\n",
      "Channel 25: EEG P10-REF\n",
      "Channel 26: EMG_4-REF\n",
      "Channel 27: Photic-REF\n"
     ]
    }
   ],
   "source": [
    "# For easier referencing of a specific channel:\n",
    "# A lookup table with the labels of all channels in the edf\n",
    "for i, sh in enumerate(signal_headers):\n",
    "    print('Channel {:2d}: {}'.format(i, sh['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35172d38",
   "metadata": {},
   "source": [
    "# Pre-Processing & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727e4ea",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "Take from Task 2, or load pre-processed data from file.\n",
    "Note that you need to filter all channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5604fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: REPLACE the following line of code!\n",
    "#       There is no need to keep it.\n",
    "signals = raw_signals.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3567f",
   "metadata": {},
   "source": [
    "## Per-channel normalisation\n",
    "The signals have per definition a zero line.\n",
    "The easiest way to go on is therefore to scale symmetrically.\n",
    "Note though that this is a plump assumption and should be replaced by\n",
    "transforming to physical units first.\n",
    "\n",
    "Why do we normalise here?\n",
    "Well, we don't have to, but it is especially helpful for methods includig probability density function (pdf) estimation (Optional Tasks 3a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea52382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to pass the values on to a new variable,\n",
    "# even if we by default do not filter the normalise\n",
    "# the signal here.\n",
    "norm_signals = None\n",
    "\n",
    "# Change to True to perform normalisation here.\n",
    "if False:\n",
    "    norm_signals = np.zeros((signals.shape[0] - 1, signals.shape[1]))\n",
    "    for i in range(signals.shape[0] - 1):\n",
    "        # Using variance should not be that sensitive to outliers as the maximum.\n",
    "        # But both perform good. For pdf estimation use max of absolute value.\n",
    "        #scaling_factor = 2 * np.sqrt(np.var(signals[i,:]))\n",
    "        scaling_factor = np.max(np.abs(signals[i,:]))\n",
    "        if scaling_factor == 0:\n",
    "            print('Channel #{} has no content!'.format(i))\n",
    "        norm_signals[i,:] = signals[i,:] / scaling_factor\n",
    "else:\n",
    "    norm_signals = signals.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28904bd1",
   "metadata": {},
   "source": [
    "## Windowing function & overlap with seizure\n",
    "There are library functions which also do this.\n",
    "This implementaion is rather raw, but illustrates the idea.\n",
    "\n",
    "We analyse the time series in terms of windows. Given a signal + header,\n",
    "we can configure the window length + overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "382c06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import windows\n",
    "    \n",
    "def interval_overlap(i1_start : float, i1_stop : float,\n",
    "            i2_start : float, i2_stop : float) -> float: \n",
    "    \n",
    "    \"\"\" A function to determine the overlap between intervals.\n",
    "\n",
    "        There are two options to implement this function.\n",
    "\n",
    "        (1) For starters, determine if there is an overlap.\n",
    "            If there is, then return 1\n",
    "\n",
    "        (2) Determine the actual overlap as a fraction in [0, 1],\n",
    "            return this value.\n",
    "    \n",
    "            Given the intervals [i1_start, i1_stop] and [i2_start, i2_stop],\n",
    "            return the overlap normalised to the smaller interval's length.\n",
    "    \n",
    "            This overlap will then be used determine how much of an interval\n",
    "            is seizure.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine if there is an overlap\n",
    "    if i1_stop < i2_start or i2_stop < i1_start:\n",
    "        return 0\n",
    "\n",
    "    # Calculate the overlap\n",
    "    overlap_start = max(i1_start, i2_start)\n",
    "    overlap_end = min(i1_stop, i2_stop)\n",
    "    overlap = overlap_end - overlap_start\n",
    "\n",
    "    # Normalize the overlap to the smaller interval's length\n",
    "    smaller_interval_length = min(i1_stop - i1_start, i2_stop - i2_start)\n",
    "    return overlap / smaller_interval_length\n",
    "\n",
    "\n",
    "def overlap_with_seizures(i1_start : float, i1_duration : float) -> float:\n",
    "    \"\"\" Determine the overlap of i1 with annotated seizures. \"\"\"\n",
    "\n",
    "    result : float = 0\n",
    "    for _start, _duration in seizures:\n",
    "        this = interval_overlap(i1_start, i1_start + i1_duration, _start, _start + _duration)\n",
    "        result += this\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def time_windows(signal, header, window_length_in_s, overlap_in_s):\n",
    "    \"\"\" Iterator over all time windows of a certain length.\n",
    "    \n",
    "        For a given signal, the return value of this function\n",
    "        can be iterated over to access all windows of specified\n",
    "        length and overlap.\n",
    "    \"\"\"\n",
    "    rate = header['sample_frequency']\n",
    "    window_length_in_samples = int(np.trunc(window_length_in_s * rate))\n",
    "    overlap_in_samples = int(np.trunc(overlap_in_s * rate))\n",
    "    step = window_length_in_samples - overlap_in_samples\n",
    "    \n",
    "    for i in range(0, len(signal), step):\n",
    "        if (len(signal) - i) < window_length_in_samples:\n",
    "            print('Information: incomplete window encountered. This is normal for the last window of a channel.')\n",
    "            return\n",
    "\n",
    "        yield (i + window_length_in_samples/2) / rate, \\\n",
    "              signal[i:i + window_length_in_samples], \\\n",
    "              overlap_with_seizures(i / rate, window_length_in_samples / rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88daec",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "For each window in each channel, we will generate a feature vector.\n",
    "The label will be determined by the overlap with the seizure annotation.\n",
    "\n",
    "General procedure:\n",
    " 1. Per-channel normalisation\n",
    " 2. Window splitting (time, signal, overlap of window with seizure annotation)\n",
    " 3. Calculation of features\n",
    " 4. Store: (time, features, label == overlap)\n",
    " \n",
    "I suggest to implement at least the following features\n",
    "  * mean\n",
    "  * variance\n",
    "  * energy\n",
    "  * area\n",
    "  * nonlinear_energy\n",
    "  * num_zero_crossings\n",
    "  * length_of_curve\n",
    "\n",
    "Please check with the lecture to get a detailed list of what is expected for a minimal implementation.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb20eaf",
   "metadata": {},
   "source": [
    "## Code for Calculating Features\n",
    "Of course, with more complex features, you are free to map this in the notebook structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac1c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature1(signal):\n",
    "    \"\"\" Calculate feature 1 on signal. \"\"\"\n",
    "    mean = np.mean(signal)\n",
    "    variance = np.var(signal)\n",
    "    energy = np.sum(signal ** 2)\n",
    "    return mean, variance, energy\n",
    "\n",
    "\n",
    "def feature2(signal):\n",
    "    \"\"\" Calculate feature 2 on signal. \"\"\"\n",
    "    area = np.sum(signal)\n",
    "    nonlinear_energy = np.sum(np.abs(np.diff(signal)) ** 2)\n",
    "    num_zero_crossing = np.sum(np.diff(np.sign(signal)) != 0)\n",
    "    length_of_curve = np.sum(np.sqrt(1 + np.diff(signal) ** 2))\n",
    "    return area, nonlinear_energy, num_zero_crossing, length_of_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c8be0",
   "metadata": {},
   "source": [
    "## Forming the Feature Vector\n",
    "Here, you actually plug in the features you want to include in the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce44e894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features per fv: 7\n"
     ]
    }
   ],
   "source": [
    "def build_feature_vector(sig):\n",
    "    \"\"\" Create a feature vector by combining all features. \"\"\"\n",
    "    return np.array([\n",
    "        *feature1(sig),\n",
    "        *feature2(sig),\n",
    "    ])\n",
    "\n",
    "# We derive the number of features automatically\n",
    "# by calling build_feature_vector with fake data.\n",
    "num_features = len(build_feature_vector(np.linspace(0, 19, 20)))\n",
    "print('Number of features per fv:', num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ba349",
   "metadata": {},
   "source": [
    "## Processing the Data\n",
    "Now perform the feature calculations and collect the feature vectors for all windows.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c483cffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for Channel #0 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #1 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #2 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #3 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #4 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #5 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #6 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #7 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #8 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #9 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #10 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #11 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #12 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #13 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #14 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #15 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #16 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #17 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #18 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #19 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #20 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #21 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #22 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #23 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #24 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #25 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #26 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "Extracting features for Channel #27 of 28\n",
      "Information: incomplete window encountered. This is normal for the last window of a channel.\n",
      "3602\n",
      "28 7 196\n",
      "(3602, 196)\n"
     ]
    }
   ],
   "source": [
    "# Per channel window splitting & feature vector creation\n",
    "# Optimisation options:\n",
    "#   * Save all windows, so that we can calculate features without window regeneration!\n",
    "#   * Extract windows for all channels at the same time\n",
    "window_length  = 3 # s\n",
    "window_overlap = 1 # s\n",
    "\n",
    "# For calculation of the number of windows\n",
    "window_length_in_samples = int(np.trunc(window_length * signal_headers[0]['sample_frequency']))\n",
    "overlap_in_samples = int(np.trunc(window_overlap * signal_headers[0]['sample_frequency']))\n",
    "\n",
    "num_channels = norm_signals.shape[0]\n",
    "num_windows = int(np.trunc(\n",
    "    (norm_signals.shape[1] - overlap_in_samples) / (window_length_in_samples - overlap_in_samples)\n",
    "))\n",
    "\n",
    "fv_times = np.zeros((num_windows))\n",
    "fvs = np.zeros((num_windows, num_channels * num_features))\n",
    "labels = np.zeros((num_windows))\n",
    "\n",
    "_window = None\n",
    "for ch_idx in range(norm_signals.shape[0]):\n",
    "    print('Extracting features for Channel #' + str(ch_idx), 'of', norm_signals.shape[0])\n",
    "    for win_idx, (start_time, win_data, overlap) in enumerate(time_windows(norm_signals[ch_idx], signal_headers[ch_idx], \n",
    "                                                                           window_length, window_overlap)):\n",
    "        fvs[win_idx, ch_idx * num_features:(ch_idx+1) * num_features] = build_feature_vector(win_data)\n",
    "        if (ch_idx == 0):\n",
    "            fv_times[win_idx] = start_time\n",
    "            labels[win_idx] = overlap\n",
    "        if (ch_idx == 0) and (win_idx == 0):\n",
    "            _window = win_data\n",
    "\n",
    "print(num_windows)\n",
    "print(num_channels, num_features, num_channels * num_features)\n",
    "print(fvs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bdd37f",
   "metadata": {},
   "source": [
    "# Classification\n",
    "Now comes the time to throw the feature vectors at different classifiers.\n",
    "But as we do not have the time to go into all the different options, we will stick to the logistic regression, which we know from Module 2 as a possible choice for classification tasks.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9659ccd",
   "metadata": {},
   "source": [
    "## Data Set Splitting\n",
    "While there are plenty of methods available to automate this part, we are here going to do it by hand, so that we can experiment with the process, i.e., you definitely want to fiddle with the balancing.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bae96ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data summary\n",
      "  Number of feature vectors: 3602\n",
      "  Size of training set: 2881\n",
      "  Size of validation set: 721\n"
     ]
    }
   ],
   "source": [
    "# Preparation of data sets for training and evaluation\n",
    "balanced = False\n",
    "test_split = 0.8\n",
    "non_seizure_overhead = 1\n",
    "\n",
    "binary_labels : np.ndarray = labels > 0\n",
    "\n",
    "train_data : np.ndarray = None\n",
    "train_labels : np.ndarray = None\n",
    "test_data : np.ndarray = None\n",
    "test_labels : np.ndarray = None\n",
    "\n",
    "if balanced:      # Select seizures (lower number), and select interictal accordingly\n",
    "    from numpy.random import default_rng\n",
    "    rng = default_rng()\n",
    "\n",
    "    num_seizure_fvs = sum(binary_labels)\n",
    "    for_training = int(np.round(test_split * num_seizure_fvs))\n",
    "    print('Number of fvs with seizure:', num_seizure_fvs)\n",
    "    print('  Number of seizure training fvs:', for_training)\n",
    "    print('  Number of seizure validation fvs:', num_seizure_fvs - for_training)\n",
    "    print('  Number of interictal validation fvs:', \n",
    "          len(binary_labels) - num_seizure_fvs - non_seizure_overhead * for_training)\n",
    "    \n",
    "    # Get indices of ictal and interictal fvs.\n",
    "    # Should we shuffle them to make sure that we get a somewhat\n",
    "    # random selection? Might be bad, because this way, especially\n",
    "    # with the low numbers, we could end up only seeing beginnings…\n",
    "    seizure_idx = np.nonzero(binary_labels >= 0.5)[0]\n",
    "    interictal_idx = np.nonzero(binary_labels < 0.5)[0]\n",
    "    \n",
    "    # The classifier fit(…) will shuffle. But just in case we do so too.\n",
    "    training_idx = np.concatenate(\n",
    "        (seizure_idx[:for_training], interictal_idx[:non_seizure_overhead * for_training])\n",
    "    )\n",
    "    np.random.shuffle(training_idx)\n",
    "    test_idx = np.concatenate(\n",
    "        (seizure_idx[for_training:], interictal_idx[non_seizure_overhead * for_training:])\n",
    "    )\n",
    "    np.random.shuffle(test_idx)\n",
    "\n",
    "    _train_data = fvs[training_idx,:]\n",
    "    train_labels = binary_labels[training_idx]\n",
    "    _test_data = fvs[test_idx,:]\n",
    "    test_labels = binary_labels[test_idx]\n",
    "    \n",
    "else:             # Just split according to test_split\n",
    "    last = int(test_split * len(binary_labels))\n",
    "\n",
    "    _train_data = fvs[:last,:]\n",
    "    train_labels = binary_labels[:last]\n",
    "    _test_data = fvs[last:,:]\n",
    "    test_labels = binary_labels[last:]\n",
    "\n",
    "print('\\nData summary')\n",
    "print('  Number of feature vectors:', fvs.shape[0])\n",
    "print('  Size of training set:', _train_data.shape[0])\n",
    "print('  Size of validation set:', _test_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b675fe",
   "metadata": {},
   "source": [
    "## Last Pre-Processing & PCA\n",
    "In this part, we investigate the improvements by using scaling and PCA for reducig dimensions and decorrelating signals.\n",
    "Please check [the scikit documentation on pre-processing](https://scikit-learn.org/stable/modules/preprocessing.html) for details on how the following settings are transforming the data.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a8ab0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimensionality: 196\n",
      "PCA performed. # reduced dimensions: 162\n",
      "   Ratio of variance explained: [0.26566913 0.1018541  0.09207284 0.08300064]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:155: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed -= xp.reshape(self.mean_, (1, -1)) @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:155: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed -= xp.reshape(self.mean_, (1, -1)) @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:155: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed -= xp.reshape(self.mean_, (1, -1)) @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:155: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed -= xp.reshape(self.mean_, (1, -1)) @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:155: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed -= xp.reshape(self.mean_, (1, -1)) @ self.components_.T\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/decomposition/_base.py:155: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed -= xp.reshape(self.mean_, (1, -1)) @ self.components_.T\n"
     ]
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "#\n",
    "# Scaling and PCA\n",
    "# Also check the order of PCA with/without whitening and scaling.\n",
    "\n",
    "do_PCA = True\n",
    "PCA_whiten = True\n",
    "PCA_n_comp = 'mle'\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class DummyScaler():\n",
    "    def fit(self, data):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return data\n",
    "\n",
    "\n",
    "# scaler = DummyScaler().fit(_train_data)\n",
    "scaler = preprocessing.StandardScaler().fit(_train_data)\n",
    "# scaler = preprocessing.RobustScaler().fit(_train_data)\n",
    "\n",
    "train_data = scaler.transform(_train_data)\n",
    "test_data = scaler.transform(_test_data)\n",
    "\n",
    "print('Original dimensionality:', _train_data.shape[1])\n",
    "\n",
    "if do_PCA:\n",
    "    # Use PCA to reduce linear dependencies\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=PCA_n_comp, svd_solver='full', whiten=PCA_whiten, copy=True)\n",
    "    pca.fit(train_data)\n",
    "    train_data = pca.transform(train_data)\n",
    "    test_data = pca.transform(test_data)\n",
    "\n",
    "    print('PCA performed. # reduced dimensions:', pca.n_components_)\n",
    "    print('   Ratio of variance explained:', pca.explained_variance_ratio_[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c193fb",
   "metadata": {},
   "source": [
    "## Optional: Inspecting the PCA's Effect\n",
    "For trying to get a feeling for how the PCA changes the channels, please plot consecutive or two otherwise selected channels on x/y axis.\n",
    "Colour the dots according to their labels.\n",
    "\n",
    "Can you find dimensions which separate the labels better than others?\n",
    "Keep them in mind when checking later the relevance of the features.\n",
    "\n",
    "This part is for trying to get a feeling of how the PCA might help the classifier,\n",
    "it is an explorative task, which means trying out, plotting, and inspecting.\n",
    "Do this only after you have completed your report, to avoid getting stuck here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ed7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "877f6408",
   "metadata": {},
   "source": [
    "# Create a Model\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95d1eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9230639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "classifier.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5adba26",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Evaluate accuracy, sensitivity, specificity, confusion matrix.\n",
    "What do these measures tell us about the performance of our model?\n",
    "\n",
    "Check which features were most relevant.\n",
    "\n",
    "**Report:** Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db1da85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the Final Classifier on the Test Set\n",
      "\n",
      "Accuracy Score: 0.9709\n",
      "\n",
      "Confusion Matrix\n",
      "[[679  12]\n",
      " [  9  21]]\n",
      "True Negatives: 679\n",
      "False Positives: 12\n",
      "False Negatives: 9\n",
      "True Positives: 21\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.98      0.98       691\n",
      "        True       0.64      0.70      0.67        30\n",
      "\n",
      "    accuracy                           0.97       721\n",
      "   macro avg       0.81      0.84      0.83       721\n",
      "weighted avg       0.97      0.97      0.97       721\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/sandbye/Documents/GitHub/summer-school-ai/summer_env/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "y_pred = classifier.predict(test_data)\n",
    "    \n",
    "print(\"Evaluation of the Final Classifier on the Test Set\")\n",
    "print(f\"\\nAccuracy Score: {accuracy_score(test_labels, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "true_negatives = cm[0, 0]\n",
    "false_positives = cm[0, 1]\n",
    "false_negatives = cm[1, 0]\n",
    "true_positives = cm[1, 1]\n",
    "print(cm)\n",
    "print(\"True Negatives:\", true_negatives) # correct prediction on non-seizure\n",
    "print(\"False Positives:\", false_positives) # incorrectly predicted non-seizure\n",
    "print(\"False Negatives:\", false_negatives) # Incorrectly predicted actual seizures\n",
    "print(\"True Positives:\", true_positives) # The model predicted correctly on actual seizures\n",
    "\n",
    "# Optional: A more detailed classification report\n",
    "print(\"\\nClassification Report\")\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03255688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
